{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import skorch\n",
    "from imageio import imread\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skorch.callbacks import LRScheduler,Checkpoint,EpochScoring,EarlyStopping\n",
    "import torch.optim as optim\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validation_test_split(index, \n",
    "                                y, \n",
    "                                validation_size=0.20, \n",
    "                                test_size=0.20,\n",
    "                                random_state=None):\n",
    "\n",
    "    train_index, test_index, y_train, _ = train_test_split( index, \n",
    "                                                y, \n",
    "                                                test_size=test_size, \n",
    "                                                stratify=y, \n",
    "                                                random_state=random_state)\n",
    "\n",
    "    train_index, validation_index, _, _ = train_test_split( train_index, \n",
    "                                                y_train, \n",
    "                                                test_size=validation_size, \n",
    "                                                stratify=y_train,\n",
    "                                                random_state=random_state)\n",
    "    return train_index, validation_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampler(metadata, n):\n",
    "    train_index = metadata.set == \"train\"\n",
    "    val_index = metadata.set == \"val\"\n",
    "    test_index = metadata.set == \"test\"\n",
    "    \n",
    "    metadata_over_sampled = pd.DataFrame(columns=[\"file\", \"label\", \"dataset\", \"set\"]) \n",
    "    \n",
    "    list_of_classes = metadata.loc[train_index, \"label\"].unique()\n",
    "    for cl in list_of_classes:\n",
    "        specific_class_index = train_index.copy()\n",
    "        specific_class_index = specific_class_index & metadata.label == cl\n",
    "        \n",
    "        metadata_dummy = metadata.loc[specific_class_index,:].sample(n, replace=True)\n",
    "        metadata_over_sampled = metadata_over_sampled.append(metadata_dummy, ignore_index = True)\n",
    "    \n",
    "    ## adding the val and test sets\n",
    "    metadata_over_sampled = metadata_over_sampled.append(metadata.loc[val_index,:], ignore_index = True)\n",
    "    metadata_over_sampled = metadata_over_sampled.append(metadata.loc[test_index,:], ignore_index = True)\n",
    "    \n",
    "    return metadata_over_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix, matthews_corrcoef, classification_report,confusion_matrix, accuracy_score, balanced_accuracy_score, cohen_kappa_score, f1_score,  precision_score, recall_score\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def classification_complete_report(y_true, y_pred ,labels = None  ): \n",
    "    print(classification_report(y_true, y_pred, labels = labels))\n",
    "    print(15*\"----\")\n",
    "    print(\"matthews correlation coeff: %.4f\" % (matthews_corrcoef(y_true, y_pred)) )\n",
    "    print(\"Cohen Kappa score: %.4f\" % (cohen_kappa_score(y_true, y_pred)) )\n",
    "    print(\"Accuracy: %.4f & balanced Accuracy: %.4f\" % (accuracy_score(y_true, y_pred), balanced_accuracy_score(y_true, y_pred)) )\n",
    "    print(\"macro F1 score: %.4f & micro F1 score: %.4f\" % (f1_score(y_true, y_pred, average = \"macro\"), f1_score(y_true, y_pred, average = \"micro\")) )\n",
    "    print(\"macro Precision score: %.4f & micro Precision score: %.4f\" % (precision_score(y_true, y_pred, average = \"macro\"), precision_score(y_true, y_pred, average = \"micro\")) )\n",
    "    print(\"macro Recall score: %.4f & micro Recall score: %.4f\" % (recall_score(y_true, y_pred, average = \"macro\"), recall_score(y_true, y_pred, average = \"micro\")) )\n",
    "    cm = confusion_matrix(y_true, y_pred,labels= labels)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "    print(15*\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Tesla P100-SXM2-16GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = {\n",
    "    \"AML\": \"/pstore/data/DS4/ssl_vs_al/data/matek/train/\",\n",
    "    \"MLL\": \"/pstore/data/DS4/ssl_vs_al/data/matek/test/\",\n",
    "    \"PBC\": \"/pstore/data/DS4/ssl_vs_al/data/matek/test/\",\n",
    "}\n",
    "\n",
    "equivalent_classes = {\n",
    "    'BAS': 'basophil',\n",
    "    'EBO': 'erythroblast',\n",
    "    'EOS': 'eosinophil',\n",
    "    'KSC': \"unknown\",\n",
    "    'LYA': 'lymphocyte',\n",
    "    'LYT': 'lymphocyte',\n",
    "    'MMZ': 'ig',\n",
    "    'MOB': 'monocyte',\n",
    "    'MON': 'monocyte',\n",
    "    'MYB': 'ig',\n",
    "    'MYO': 'ig',\n",
    "    'NGB': 'neutrophil',\n",
    "    'NGS': 'neutrophil',\n",
    "    'PMB': 'ig',\n",
    "    'PMO': 'ig',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def finding_classes(data_dir):\n",
    "    \"\"\"\n",
    "    this function finds the folders in the root path and considers them\n",
    "    as classes\n",
    "    \"\"\"\n",
    "    classes = sorted(os.listdir(data_dir))\n",
    "    return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_generator(data_path):\n",
    "    \n",
    "    metadata = pd.DataFrame(columns=[\"file\", \"label\", \"dataset\", \"set\"])\n",
    "    for ds in data_path:\n",
    "        list_of_classes = finding_classes(data_path[ds])\n",
    "        for cl in list_of_classes:\n",
    "            \n",
    "            metadata_dummy = pd.DataFrame(columns=[\"file\", \"label\", \"dataset\", \"set\"])\n",
    "            metadata_dummy[\"file\"] = glob(os.path.join(data_path[ds], cl, \"*\"))\n",
    "            metadata_dummy[\"label\"] = cl\n",
    "            metadata_dummy[\"dataset\"] = ds\n",
    "            metadata_dummy[\"set\"] = \"train\"\n",
    "            metadata = metadata.append(metadata_dummy, ignore_index=True)\n",
    "            metadata_dummy = None\n",
    "    return metadata\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata_generator(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.label = metadata.label.replace(equivalent_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## leave unknown class out\n",
    "known_index = metadata.label != \"unknown\"\n",
    "metadata = metadata.loc[known_index,:].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_index, val_index, test_index = train_validation_test_split(metadata.index, \n",
    "                                                                 y = metadata.label,\n",
    "                                                                random_state = 314)\n",
    "\n",
    "metadata.loc[train_index, \"set\"] = \"train\"\n",
    "\n",
    "metadata.loc[val_index, \"set\"] = \"val\"\n",
    "\n",
    "metadata.loc[test_index, \"set\"] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22015</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22016</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22017</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22018</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22019</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22020 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file     label dataset  \\\n",
       "0      /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...  basophil     AML   \n",
       "1      /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...  basophil     AML   \n",
       "2      /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...  basophil     AML   \n",
       "3      /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...  basophil     AML   \n",
       "4      /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...  basophil     AML   \n",
       "...                                                  ...       ...     ...   \n",
       "22015  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "22016  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "22017  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "22018  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "22019  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "\n",
       "         set  \n",
       "0      train  \n",
       "1      train  \n",
       "2      train  \n",
       "3      train  \n",
       "4       test  \n",
       "...      ...  \n",
       "22015  train  \n",
       "22016   test  \n",
       "22017  train  \n",
       "22018  train  \n",
       "22019  train  \n",
       "\n",
       "[22020 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basophil': 0,\n",
       " 'erythroblast': 1,\n",
       " 'eosinophil': 2,\n",
       " 'lymphocyte': 3,\n",
       " 'ig': 4,\n",
       " 'monocyte': 5,\n",
       " 'neutrophil': 6}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = dict()\n",
    "\n",
    "for i,cl in enumerate(metadata.label.unique()):\n",
    "    label_map[cl] = i\n",
    "    \n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def over_sampler(metadata, n):\n",
    "    train_index = metadata.set == \"train\"\n",
    "    \n",
    "    metadata_over_sampled = pd.DataFrame(columns=[\"file\", \n",
    "                                                  \"label\", \n",
    "                                                  \"dataset\", \n",
    "                                                  \"set\"]) \n",
    "    \n",
    "    list_of_classes = metadata.loc[train_index, \"label\"].unique()\n",
    "    for cl in list_of_classes:\n",
    "        specific_class_index = train_index.copy()\n",
    "        specific_class_index = specific_class_index & (metadata.label == cl)\n",
    "        \n",
    "        metadata_dummy = metadata.loc[specific_class_index,:].sample(n, replace=True)\n",
    "        metadata_over_sampled = metadata_over_sampled.append(metadata_dummy, ignore_index = True)\n",
    "    \n",
    "    return metadata_over_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_over_sampled = over_sampler(metadata, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/BA...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/NGS...</td>\n",
       "      <td>neutrophil</td>\n",
       "      <td>MLL</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/NG...</td>\n",
       "      <td>neutrophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/NGS...</td>\n",
       "      <td>neutrophil</td>\n",
       "      <td>MLL</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/NG...</td>\n",
       "      <td>neutrophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/train/NG...</td>\n",
       "      <td>neutrophil</td>\n",
       "      <td>AML</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  file       label dataset  \\\n",
       "0    /pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...    basophil     PBC   \n",
       "1    /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...    basophil     AML   \n",
       "2    /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...    basophil     AML   \n",
       "3    /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...    basophil     AML   \n",
       "4    /pstore/data/DS4/ssl_vs_al/data/matek/train/BA...    basophil     AML   \n",
       "..                                                 ...         ...     ...   \n",
       "695  /pstore/data/DS4/ssl_vs_al/data/matek/test/NGS...  neutrophil     MLL   \n",
       "696  /pstore/data/DS4/ssl_vs_al/data/matek/train/NG...  neutrophil     AML   \n",
       "697  /pstore/data/DS4/ssl_vs_al/data/matek/test/NGS...  neutrophil     MLL   \n",
       "698  /pstore/data/DS4/ssl_vs_al/data/matek/train/NG...  neutrophil     AML   \n",
       "699  /pstore/data/DS4/ssl_vs_al/data/matek/train/NG...  neutrophil     AML   \n",
       "\n",
       "       set  \n",
       "0    train  \n",
       "1    train  \n",
       "2    train  \n",
       "3    train  \n",
       "4    train  \n",
       "..     ...  \n",
       "695  train  \n",
       "696  train  \n",
       "697  train  \n",
       "698  train  \n",
       "699  train  \n",
       "\n",
       "[700 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_over_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "\n",
    "class DatasetGenerator(Dataset):\n",
    "\n",
    "    def __init__(self, \n",
    "                metadata, \n",
    "                reshape_size=64, \n",
    "                label_map=[],\n",
    "                dataset = [],\n",
    "                transform=None,\n",
    "                selected_channels = [0]):\n",
    "        \n",
    "        dataset_index = metadata.dataset.isin(dataset)\n",
    "        self.metadata = metadata.loc[dataset_index,:].copy()\n",
    "        self.metadata = self.metadata.copy().reset_index(drop = True)\n",
    "        \n",
    "        self.reshape_size = reshape_size\n",
    "        self.label_map = label_map\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        ## get image and label\n",
    "        h5_file_path = self.metadata.loc[idx,\"file\"]\n",
    "        image= imread(h5_file_path)[:,:,selected_channels]\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        label = self.metadata.loc[idx,\"label\"]\n",
    " \n",
    "\n",
    "        # map numpy array to tensor\n",
    "        image = torch.from_numpy(copy.deepcopy(image)) \n",
    "        image = image.float()\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image) \n",
    "        \n",
    "        label = self.label_map[label]\n",
    "        label = torch.tensor(label).long()\n",
    "        return image.float(),  label\n",
    "        \n",
    "        \n",
    "\n",
    "def get_statistics(dataloader, nmb_channels ):\n",
    "\n",
    "    statistics = dict()\n",
    "    \n",
    "    statistics[\"mean\"] = torch.zeros(nmb_channels)\n",
    "    statistics[\"std\"] = torch.zeros(nmb_channels)\n",
    "    for _, data_l in enumerate(tqdm(dataloader), 0):\n",
    "        image, _ = data_l\n",
    "        for n in range(nmb_channels):\n",
    "\n",
    "            statistics[\"mean\"][n] += image[:, n, :, :].mean()\n",
    "            statistics[\"std\"][n] += image[:, n, :, :].std()\n",
    "\n",
    "    # averaging\n",
    "    for k in statistics:\n",
    "        statistics[k] = statistics[k].div_(len(dataloader))\n",
    "\n",
    "    print('statistics used: %s' % (str(statistics)))\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = metadata.set == \"train\"\n",
    "val_index = metadata.set == \"val\"\n",
    "test_index = metadata.set == \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_size = 64\n",
    "\n",
    "train_dataset = DatasetGenerator(metadata.loc[train_index ,:], # metadata_over_sampled\n",
    "                                 reshape_size=reshape_size, \n",
    "                                label_map=label_map,\n",
    "                                 dataset = [\"PBC\",\"MLL\"],\n",
    "                                transform=None,\n",
    "                                selected_channels=selected_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>MLL</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>MLL</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>MLL</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>MLL</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...</td>\n",
       "      <td>basophil</td>\n",
       "      <td>MLL</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4703</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>/pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...</td>\n",
       "      <td>ig</td>\n",
       "      <td>PBC</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4708 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   file     label dataset  \\\n",
       "0     /pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...  basophil     MLL   \n",
       "1     /pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...  basophil     MLL   \n",
       "2     /pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...  basophil     MLL   \n",
       "3     /pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...  basophil     MLL   \n",
       "4     /pstore/data/DS4/ssl_vs_al/data/matek/test/BAS...  basophil     MLL   \n",
       "...                                                 ...       ...     ...   \n",
       "4703  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "4704  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "4705  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "4706  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "4707  /pstore/data/DS4/ssl_vs_al/data/matek/test/PMO...        ig     PBC   \n",
       "\n",
       "        set  \n",
       "0     train  \n",
       "1     train  \n",
       "2     train  \n",
       "3     train  \n",
       "4     train  \n",
       "...     ...  \n",
       "4703  train  \n",
       "4704  train  \n",
       "4705  train  \n",
       "4706  train  \n",
       "4707  train  \n",
       "\n",
       "[4708 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 64, shuffle = True, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = get_statistics(train_loader,nmb_channels=len(selected_channels) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResNet18Pretrained(nn.Module):\n",
    "    def __init__(self,  \n",
    "                 num_channels=3, \n",
    "                 num_classes=3, \n",
    "                 pretrained=True ,**kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        model = resnet18(pretrained=True) \n",
    "        if num_channels != 3:\n",
    "            model.conv1 = nn.Conv2d(num_channels, 64, kernel_size=(7, 7),\n",
    "                                        stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):                \n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_pretrained = ResNet18Pretrained(num_channels=3 , num_classes = len(metadata.label.unique()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import transforms\n",
    "eps = 1e-16\n",
    "stats[\"std\"] = stats[\"std\"] + eps\n",
    "train_transform = transforms.Compose([ \n",
    "        torchvision.transforms.Normalize(\n",
    "                mean=stats[\"mean\"],\n",
    "                std=stats[\"std\"],\n",
    "            ),\n",
    "        transforms.RandomResizedCrop(reshape_size, scale=(0.8, 1.0), ratio=(0.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        AddGaussianNoise(mean=0., std=0.02),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = DatasetGenerator(metadata.loc[train_index ,:], \n",
    "                                 reshape_size=reshape_size, \n",
    "                                 dataset = [\"PBC\",\"MLL\"],\n",
    "                                label_map=label_map, \n",
    "                                 transform = train_transform)\n",
    "\n",
    "val_transform = transforms.Compose([ \n",
    "        torchvision.transforms.Normalize(\n",
    "                mean=stats[\"mean\"],\n",
    "                std=stats[\"std\"],\n",
    "            ),\n",
    "        transforms.Resize(reshape_size)])\n",
    "\n",
    "\n",
    "val_dataset = DatasetGenerator(metadata.loc[val_index,:], \n",
    "                                 reshape_size=reshape_size, \n",
    "                                 dataset = [\"PBC\",\"MLL\"],\n",
    "                                label_map=label_map, \n",
    "                                 transform = val_transform)\n",
    "\n",
    "\n",
    "\n",
    "test_dataset = DatasetGenerator(metadata.loc[test_index,:], \n",
    "                                 reshape_size=reshape_size, \n",
    "                                 dataset = [\"AML\"],\n",
    "                                label_map=label_map, \n",
    "                                 transform = val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_dataset[0][0][0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr_scheduler = LRScheduler(policy='StepLR', step_size=5, gamma=0.6)\n",
    "checkpoint = Checkpoint(f_params='resnet_18_aml.pth', monitor='valid_acc_best')\n",
    "\n",
    "\n",
    "epoch_scoring = EpochScoring(\"f1_macro\", name = \n",
    "                       \"valid_f1_macro\",\n",
    "                       on_train = False,\n",
    "                       lower_is_better = False)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='valid_f1_macro', \n",
    "                               patience=50, \n",
    "                               threshold=0.0001, \n",
    "                               threshold_mode='rel', \n",
    "                               lower_is_better=False)\n",
    "\n",
    "model = NeuralNetClassifier(    \n",
    "    resnet_pretrained, \n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    lr=0.001,\n",
    "    batch_size=64,\n",
    "    max_epochs=1000,\n",
    "    optimizer=optim.Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=3,\n",
    "    iterator_valid__shuffle=False,\n",
    "    iterator_valid__num_workers=1,\n",
    "    callbacks=[lr_scheduler,checkpoint, epoch_scoring, early_stopping],\n",
    "    train_split=predefined_split(val_dataset),\n",
    "    device=\"cuda\",\n",
    "    warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(train_dataset, y = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.load_state_dict(torch.load('resnet_18_aml.pth')) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(val_dataset)\n",
    "\n",
    "classification_complete_report([label_map[t] for t in val_dataset.metadata.label], \n",
    "                               preds  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_dataset)\n",
    "#preds =  [inv_map[int(t)] for t in preds]\n",
    "\n",
    "classification_complete_report([label_map[t] for t in test_dataset.metadata.label],  preds   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
